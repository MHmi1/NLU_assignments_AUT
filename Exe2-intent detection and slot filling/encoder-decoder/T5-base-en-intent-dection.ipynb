{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T13:43:52.028391Z",
     "iopub.status.busy": "2024-12-20T13:43:52.028087Z",
     "iopub.status.idle": "2024-12-20T13:43:52.366007Z",
     "shell.execute_reply": "2024-12-20T13:43:52.365153Z",
     "shell.execute_reply.started": "2024-12-20T13:43:52.028364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def create_tokens_and_labels(id, sample):\n",
    "    intent = sample['intent']\n",
    "    utt = sample['utt']\n",
    "    annot_utt = sample['annot_utt']\n",
    "    tokens = utt.split()\n",
    "    labels = []\n",
    "    label = 'O'\n",
    "    split_annot_utt = annot_utt.split()\n",
    "    idx = 0\n",
    "    BIO_SLOT = False\n",
    "    while idx < len(split_annot_utt):\n",
    "        if split_annot_utt[idx].startswith('['):\n",
    "            label = split_annot_utt[idx].lstrip('[')\n",
    "            idx += 2\n",
    "            BIO_SLOT = True\n",
    "        elif split_annot_utt[idx].endswith(']'):\n",
    "            if split_annot_utt[idx-1] == \":\":\n",
    "                labels.append(\"B-\" + label)\n",
    "                label = 'O'\n",
    "                idx += 1\n",
    "            else:\n",
    "                labels.append(\"I-\" + label)\n",
    "                label = 'O'\n",
    "                idx += 1\n",
    "            BIO_SLOT = False\n",
    "        else:\n",
    "            if split_annot_utt[idx-1] == \":\":\n",
    "                labels.append(\"B-\" + label)\n",
    "                idx += 1\n",
    "            elif BIO_SLOT == True:\n",
    "                labels.append(\"I-\" + label)\n",
    "                idx += 1\n",
    "            else:\n",
    "                labels.append(\"O\")\n",
    "                idx += 1\n",
    "\n",
    "    if len(tokens) != len(labels):\n",
    "        raise ValueError(f\"Len of tokens, {tokens}, doesnt match len of labels, {labels}, \"\n",
    "                         f\"for id {id} and annot utt: {annot_utt}\")\n",
    "    return tokens, labels, intent\n",
    "\n",
    "\n",
    "def Read_Massive_dataset(massive_raw):\n",
    "    sentences_tr, tags_tr, intent_tags_tr = [], [], []\n",
    "    sentences_val, tags_val, intent_tags_val = [], [], []\n",
    "    sentences_test, tags_test, intent_tags_test = [], [], []\n",
    "    all_tags, all_intents = [], []\n",
    "\n",
    "    for id, sample in enumerate(massive_raw):\n",
    "        if sample['partition'] == 'train':\n",
    "            tokens, labels, intent = create_tokens_and_labels(id, sample)\n",
    "            sentences_tr.append(tokens)\n",
    "            tags_tr.append(labels)\n",
    "            intent_tags_tr.append(intent)\n",
    "            all_tags.extend(labels)\n",
    "            all_intents.append(intent)\n",
    "        elif sample['partition'] == 'dev':\n",
    "            tokens, labels, intent = create_tokens_and_labels(id, sample)\n",
    "            sentences_val.append(tokens)\n",
    "            tags_val.append(labels)\n",
    "            intent_tags_val.append(intent)\n",
    "        elif sample['partition'] == 'test':\n",
    "            tokens, labels, intent = create_tokens_and_labels(id, sample)\n",
    "            sentences_test.append(tokens)\n",
    "            tags_test.append(labels)\n",
    "            intent_tags_test.append(intent)\n",
    "\n",
    "    # Unique labels and intents\n",
    "    unique_tags = sorted(set(all_tags))\n",
    "    unique_intents = sorted(set(all_intents))\n",
    "    tag2id = {tag: i for i, tag in enumerate(unique_tags)}\n",
    "    intent2id = {intent: i for i, intent in enumerate(unique_intents)}\n",
    "\n",
    "    return (sentences_tr, tags_tr, intent_tags_tr), \\\n",
    "           (sentences_val, tags_val, intent_tags_val), \\\n",
    "           (sentences_test, tags_test, intent_tags_test), \\\n",
    "           tag2id, intent2id\n",
    "\n",
    "#Read the dataset\n",
    "massive_raw_fa = []\n",
    "with open('/kaggle/input/english-massive/en-US.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        massive_raw_fa.append(json.loads(line))\n",
    "\n",
    "(train_data, val_data, test_data, tag2id, intent2id) = Read_Massive_dataset(massive_raw_fa)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T13:44:12.302346Z",
     "iopub.status.busy": "2024-12-20T13:44:12.301995Z",
     "iopub.status.idle": "2024-12-20T13:57:05.433535Z",
     "shell.execute_reply": "2024-12-20T13:57:05.432602Z",
     "shell.execute_reply.started": "2024-12-20T13:44:12.302316Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75738870e8194ab495f05a4b36de59a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6765c85ff3254bc885100dac08838e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:42<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 5.193860990802447, accuracy: 0.10613166579815876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Accuracy: 0.3782587309394983\n",
      "  Micro - Precision: 0.3782587309394983, Recall: 0.3782587309394983, F1: 0.3782587309394983\n",
      "  Macro - Precision: 0.1582080383108063, Recall: 0.14761322084532613, F1: 0.12353785557084085\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:41<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.3190659527149466, accuracy: 0.47507382317179087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Accuracy: 0.719626168224299\n",
      "  Micro - Precision: 0.719626168224299, Recall: 0.719626168224299, F1: 0.7196261682242989\n",
      "  Macro - Precision: 0.5785149261768234, Recall: 0.5230503089613251, F1: 0.5246837516856118\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:41<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.3211041220981214, accuracy: 0.6797811360083377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Accuracy: 0.7924249877029022\n",
      "  Micro - Precision: 0.7924249877029022, Recall: 0.7924249877029022, F1: 0.7924249877029023\n",
      "  Macro - Precision: 0.7244089362472615, Recall: 0.6709524062545935, F1: 0.6768279185575692\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:41<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9697164637554023, accuracy: 0.7603786694458919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Accuracy: 0.8332513526807673\n",
      "  Micro - Precision: 0.8332513526807673, Recall: 0.8332513526807673, F1: 0.8332513526807673\n",
      "  Macro - Precision: 0.7697409216458728, Recall: 0.7319692358332383, F1: 0.7363799317513581\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:43<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8062112050855326, accuracy: 0.7937293729372937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Accuracy: 0.8524348253812101\n",
      "  Micro - Precision: 0.8524348253812101, Recall: 0.8524348253812101, F1: 0.85243482538121\n",
      "  Macro - Precision: 0.8036408848492083, Recall: 0.781687523638494, F1: 0.7842911430802975\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:43<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6756602637107587, accuracy: 0.827340628799722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Accuracy: 0.8593212001967536\n",
      "  Micro - Precision: 0.8593212001967536, Recall: 0.8593212001967536, F1: 0.8593212001967535\n",
      "  Macro - Precision: 0.8182593861078354, Recall: 0.7978837020662012, F1: 0.7995672130569388\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:44<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5936669622547924, accuracy: 0.84627410109432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "  Accuracy: 0.8726020659124447\n",
      "  Micro - Precision: 0.8726020659124447, Recall: 0.8726020659124447, F1: 0.8726020659124447\n",
      "  Macro - Precision: 0.8318694417618933, Recall: 0.8221643446929787, F1: 0.8220569878556814\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer, AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "\n",
    "# Load T5-large\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "def encode_data(sentences, intents, tokenizer, intent2id):\n",
    "    encodings = tokenizer(sentences, is_split_into_words=True, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    intent_labels = [intent2id[intent] for intent in intents]\n",
    "    return encodings, torch.tensor(intent_labels)\n",
    "\n",
    "###################\n",
    "def encode_data(sentences, intents, tokenizer, intent2id):\n",
    "    sentences = [\" \".join(sentence) for sentence in sentences]\n",
    "    encodings = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    intent_labels = [intent2id[intent] for intent in intents]\n",
    "    return encodings, torch.tensor(intent_labels)\n",
    "\n",
    "# Encode data\n",
    "train_encodings, train_intents = encode_data(train_data[0], train_data[2], tokenizer, intent2id)\n",
    "val_encodings, val_intents = encode_data(val_data[0], val_data[2], tokenizer, intent2id)\n",
    "\n",
    "# Convert encodings to tensors for DataLoader\n",
    "def convert_to_tensor(encodings, labels):\n",
    "    input_ids = encodings['input_ids']\n",
    "    attention_mask = encodings['attention_mask']\n",
    "    labels = labels\n",
    "    return TensorDataset(input_ids, attention_mask, labels)\n",
    "\n",
    "train_dataset = convert_to_tensor(train_encodings, train_intents)\n",
    "val_dataset = convert_to_tensor(val_encodings, val_intents)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "model.config.num_labels = len(intent2id)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Initialize loss function without class weights\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for data in tqdm(data_loader):\n",
    "        input_ids, attention_mask, labels = [t.to(device) for t in data]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        decoder_input_ids = torch.full((input_ids.shape[0], 1), model.config.decoder_start_token_id, dtype=torch.long, device=input_ids.device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)\n",
    "        logits = outputs.logits[:, -1, :]  # Take the last token's logits for classification\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels).item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return correct_predictions / len(data_loader.dataset), total_loss / len(data_loader)\n",
    "#####################\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            input_ids, attention_mask, labels = [t.to(device) for t in data]\n",
    "            \n",
    "            # Similar to training, we need to specify decoder_input_ids:\n",
    "            decoder_input_ids = torch.full((input_ids.shape[0], 1), model.config.decoder_start_token_id, dtype=torch.long, device=input_ids.device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)\n",
    "            logits = outputs.logits[:, -1, :]  # We look at the logits of the last token for classification\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate both micro and macro metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(all_labels, all_preds, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_micro': recall_micro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro\n",
    "    }\n",
    "\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 4\n",
    "best_val_f1 = float('-inf')  \n",
    "early_stop_counter = 0\n",
    "\n",
    "# Training loop with early stopping\n",
    "epochs = 7\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, optimizer, device, loss_fn)\n",
    "    print(f\"Train loss: {train_loss}, accuracy: {train_acc}\")\n",
    "\n",
    "    val_metrics = eval_model(model, val_loader, device)\n",
    "    print(f\"Validation Metrics:\")\n",
    "    print(f\"  Accuracy: {val_metrics['accuracy']}\")\n",
    "    print(f\"  Micro - Precision: {val_metrics['precision_micro']}, Recall: {val_metrics['recall_micro']}, F1: {val_metrics['f1_micro']}\")\n",
    "    print(f\"  Macro - Precision: {val_metrics['precision_macro']}, Recall: {val_metrics['recall_macro']}, F1: {val_metrics['f1_macro']}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_metrics['f1_macro'] > best_val_f1:  \n",
    "        best_val_f1 = val_metrics['f1_macro']\n",
    "        early_stop_counter = 0\n",
    "        model.save_pretrained('t5_base_intent-english-best.bin')  # Save the best model\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:06:39.098099Z",
     "iopub.status.busy": "2024-12-20T14:06:39.097805Z",
     "iopub.status.idle": "2024-12-20T14:06:39.472427Z",
     "shell.execute_reply": "2024-12-20T14:06:39.471558Z",
     "shell.execute_reply.started": "2024-12-20T14:06:39.098075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: nice lyrics\n",
      "True Intent: music_likeness\n",
      "Predicted Intent: music_likeness\n",
      "--------------------------------------------------\n",
      "Text: please check my reminders\n",
      "True Intent: calendar_query\n",
      "Predicted Intent: calendar_query\n",
      "--------------------------------------------------\n",
      "Text: go on sweet talk me\n",
      "True Intent: general_quirky\n",
      "Predicted Intent: general_quirky\n",
      "--------------------------------------------------\n",
      "Text: add paav bhaji in menu card\n",
      "True Intent: lists_createoradd\n",
      "Predicted Intent: takeaway_order\n",
      "--------------------------------------------------\n",
      "Text: check recent to do list\n",
      "True Intent: lists_query\n",
      "Predicted Intent: lists_query\n",
      "--------------------------------------------------\n",
      "Text: delete list for groceries\n",
      "True Intent: lists_remove\n",
      "Predicted Intent: lists_remove\n",
      "--------------------------------------------------\n",
      "Text: change the music mode to rock\n",
      "True Intent: music_settings\n",
      "Predicted Intent: play_music\n",
      "--------------------------------------------------\n",
      "Text: what is the definition of forensic\n",
      "True Intent: qa_definition\n",
      "Predicted Intent: qa_definition\n",
      "--------------------------------------------------\n",
      "Text: what time are the hockey games tonight\n",
      "True Intent: general_quirky\n",
      "Predicted Intent: calendar_query\n",
      "--------------------------------------------------\n",
      "Text: how long will it take to get to the airport\n",
      "True Intent: transport_query\n",
      "Predicted Intent: transport_query\n",
      "--------------------------------------------------\n",
      "Text: stop audiobook\n",
      "True Intent: play_audiobook\n",
      "Predicted Intent: play_audiobook\n",
      "--------------------------------------------------\n",
      "Text: what color is a dragon fruit\n",
      "True Intent: qa_factoid\n",
      "Predicted Intent: qa_factoid\n",
      "--------------------------------------------------\n",
      "Text: i want to know what supermarket near me has the best price on gluten free bread\n",
      "True Intent: recommendation_locations\n",
      "Predicted Intent: recommendation_locations\n",
      "--------------------------------------------------\n",
      "Text: siri open twitter tweet at potus sucks\n",
      "True Intent: social_post\n",
      "Predicted Intent: social_post\n",
      "--------------------------------------------------\n",
      "Text: play ping pong\n",
      "True Intent: play_game\n",
      "Predicted Intent: play_game\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def predict_example(text, tokenizer, model, intent2id):\n",
    "    encoding = tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    decoder_input_ids = torch.full((input_ids.shape[0], 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "    logits = outputs.logits[:, -1, :]  \n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    predicted_intent = list(intent2id.keys())[list(intent2id.values()).index(predicted_class)]\n",
    "    return predicted_intent\n",
    "    \n",
    "import random\n",
    "num_examples = 15\n",
    "random_indices = random.sample(range(len(test_data[0])), num_examples)\n",
    "\n",
    "for idx in random_indices:\n",
    "    text = ' '.join(test_data[0][idx]) \n",
    "    true_intent = test_data[2][idx]  \n",
    "\n",
    "    predicted_intent = predict_example(text, tokenizer, model, intent2id)\n",
    "\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"True Intent: {true_intent}\")\n",
    "    print(f\"Predicted Intent: {predicted_intent}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T14:05:12.223730Z",
     "iopub.status.busy": "2024-12-20T14:05:12.223384Z",
     "iopub.status.idle": "2024-12-20T14:06:21.152262Z",
     "shell.execute_reply": "2024-12-20T14:06:21.151531Z",
     "shell.execute_reply.started": "2024-12-20T14:05:12.223700Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'test_set_predictions-final.csv'\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "\n",
    "def predict_example(text, tokenizer, model, intent2id):\n",
    "    encoding = tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    decoder_input_ids = torch.full((input_ids.shape[0], 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "    logits = outputs.logits[:, -1, :]  \n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    predicted_intent = list(intent2id.keys())[list(intent2id.values()).index(predicted_class)]\n",
    "    return predicted_intent\n",
    "\n",
    "import pandas as pd\n",
    "# Prepare data for prediction\n",
    "results = []\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "# Load the model\n",
    "model =T5ForConditionalGeneration.from_pretrained('/kaggle/working/t5_base_intent-english-best.bin')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "for idx, (sentence, true_intent, id) in enumerate(zip(test_data[0], test_data[2], [entry['id'] for entry in massive_raw_fa if entry['partition'] == 'test'])):\n",
    "    text = ' '.join(sentence)  # Join tokens into text\n",
    "    predicted_intent = predict_example(text, tokenizer, model, intent2id)\n",
    "    results.append({\n",
    "        'id': id,\n",
    "        'text': text,\n",
    "        'true_intent': true_intent,\n",
    "        'predicted_intent': predicted_intent\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv('en-t5-base_test_set_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'test_set_predictions-final.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6328854,
     "sourceId": 10235239,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6329154,
     "sourceId": 10235621,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
